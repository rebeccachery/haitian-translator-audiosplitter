{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebeccachery/haitian-translator-audiosplitter/blob/main/AudioSilenceSpliter_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get(\"OPEN_AI\")\n",
        "except Exception:\n",
        "    api_key = None\n",
        "\n",
        "if not api_key:\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    api_key = input(\"Enter your OpenAI API key: \").strip()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "print(\"OpenAI client initialized successfully.\")\n"
      ],
      "metadata": {
        "id": "ypmaL-MnrXxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L72Bd1Lv6jf"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp pydub ffmpeg openai-whisper numpy librosa openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from urllib.parse import urlparse, parse_qs\n"
      ],
      "metadata": {
        "id": "f3hxPHqev_sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def extract_youtube_id(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc in [\"www.youtube.com\", \"youtube.com\"]:\n",
        "        query_params = parse_qs(parsed_url.query)\n",
        "        return query_params.get(\"v\", [None])[0]\n",
        "    elif parsed_url.netloc in [\"youtu.be\"]:  # Handle shortened YouTube URLs\n",
        "        return parsed_url.path.lstrip(\"/\")\n",
        "    return None\n",
        "\n",
        "def download_audio(youtube_url, output_path=\"audio.mp3\"):\n",
        "    \"\"\"Download audio from a YouTube video.\"\"\"\n",
        "\n",
        "    ydl_opts = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"outtmpl\": output_path,\n",
        "        \"postprocessors\": [{\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"mp3\",\n",
        "            \"preferredquality\": \"192\"\n",
        "        }],\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "\n",
        "    print(f\"Downloaded audio saved as {output_path}\")\n",
        "\n",
        "def convert_to_wav(input_path=\"audio.mp3\", output_path=\"audio.wav\"):\n",
        "    \"\"\"Convert MP3 to WAV with 16kHz sample rate.\"\"\"\n",
        "    audio = AudioSegment.from_file(input_path)\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1)\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    print(f\"Converted to WAV: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def split_audio_on_silence(audio_path,name, min_silence_len=800, silence_thresh=-40):\n",
        "    \"\"\"Splits audio into smaller chunks based on silence.\"\"\"\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "    chunks = split_on_silence(audio,\n",
        "                              min_silence_len=min_silence_len,  # Silence duration (in ms)\n",
        "                              silence_thresh=silence_thresh,    # Silence threshold in dB\n",
        "                              keep_silence=400)                 # Keep some silence for context\n",
        "\n",
        "    chunk_paths = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_path = f\"{name}/chunk_{i}.wav\"\n",
        "        chunk.export(chunk_path, format=\"wav\")\n",
        "        chunk_paths.append(chunk_path)\n",
        "\n",
        "    print(f\"Split audio into {len(chunks)} chunks.\")\n",
        "    return chunk_paths\n",
        "\n",
        "def transcribe_chunks(chunk_paths,name, model_size=\"small\"):\n",
        "    \"\"\"Transcribes each audio chunk using Whisper.\"\"\"\n",
        "    # model = whisper.load_model(model_size)\n",
        "\n",
        "\n",
        "    transcript_data = []\n",
        "\n",
        "    for i, chunk_path in enumerate(chunk_paths):\n",
        "        print(f\"Transcribing {chunk_path}...\")\n",
        "        audio, sr = librosa.load(chunk_path, sr=16000)  # Load with 16kHz sample rate\n",
        "        with open(chunk_path, \"rb\") as audio_file:\n",
        "          result = client.audio.transcriptions.create(\n",
        "          model=\"gpt-4o-transcribe\",\n",
        "          file=audio_file # Pass the file-like object\n",
        "          )\n",
        "\n",
        "        transcript_data.append({\n",
        "            \"chunk_id\": i,\n",
        "            \"file\": chunk_path,\n",
        "            \"transcription\": result.text\n",
        "        })\n",
        "\n",
        "    return transcript_data\n",
        "\n",
        "def save_transcription(transcript_data, output_file=\"transcription.json\"):\n",
        "    \"\"\"Saves transcription data as a JSON file.\"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(transcript_data, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"Transcription saved to {output_file}\")"
      ],
      "metadata": {
        "id": "hmvSA7NVv__c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Example Usage\n",
        "video_url = \"https://www.youtube.com/watch?v=S2ejTQtXdZM&t=21s\"\n",
        "\n",
        "\"\"\"Complete pipeline: Download, split, transcribe, and save results.\"\"\"\n",
        "\n",
        "download_audio(video_url, \"audio\")\n",
        "\n",
        "name = extract_youtube_id(video_url)\n",
        "\n",
        "os.makedirs(name, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "K7oQYYb3wAVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pK4yZSuante3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav_path = convert_to_wav(\"audio.mp3\", \"audio.wav\")\n",
        "chunk_paths = split_audio_on_silence(wav_path,name)\n"
      ],
      "metadata": {
        "id": "3rbFUcMhwA2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_data = transcribe_chunks(chunk_paths,name)\n",
        "save_transcription(transcript_data,f\"{name}/transcription.json\")"
      ],
      "metadata": {
        "id": "nwvHiOb1kDp4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = AudioSegment.from_file(f\"{name}/chunk_4.wav\", format=\"wav\")\n",
        "audio"
      ],
      "metadata": {
        "id": "O9EInqY65-ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}